{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e876fd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üïµÔ∏è‚Äç‚ôÇÔ∏è Starting Leakage Audit on cuda ---\n",
      "Lazy loading labels for ['hair_color', 'glasses', 'face_shape', 'face_color']...\n",
      "Dataset pr√™t avec 5000 images.\n",
      "‚úÖ Poids du mod√®le charg√©s.\n",
      "Extraction des vecteurs Latents (z_c)...\n",
      "Extraction termin√©e. Shape: (5000, 16)\n",
      "\n",
      "================================================================================\n",
      "ATTRIBUT        | ACCURACY   | BASELINE   | STATUS\n",
      "================================================================================\n",
      "hair_color      | 93.4%    | 10.6%    | ‚úÖ OK (Supervis√©)\n",
      "glasses         | 62.9%    | 50.1%    | ‚ùå LEAKAGE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Z\\Desktop\\ccvaes\\ccvae_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 2000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=2000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face_shape      | 18.6%    | 15.6%    | ‚úÖ DISENTANGLED\n",
      "face_color      | 34.9%    | 9.6%    | ‚ùå LEAKAGE\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Z\\Desktop\\ccvaes\\ccvae_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 2000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=2000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Imports de ton mod√®le\n",
    "from model import CCVAE \n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATA_DIR = \"./cartoonset10k/cartoonset10k\"  # Ton dossier d'images\n",
    "MODEL_PATH = \"ccvae_haircolor.pth\"           # Ton mod√®le entra√Æn√© avec Contrastive Loss\n",
    "SAMPLE_LIMIT = 5000                          # Nombre d'images pour le test\n",
    "\n",
    "# Les attributs qu'on veut tester\n",
    "PROBE_ATTRIBUTES = [\"hair_color\", \"glasses\", \"face_shape\", \"face_color\"]\n",
    "\n",
    "print(f\"--- üïµÔ∏è‚Äç‚ôÇÔ∏è Starting Leakage Audit on {DEVICE} ---\")\n",
    "\n",
    "# --- 2. D√âFINITION D'UN DATASET FLEXIBLE (Juste pour ce test) ---\n",
    "class CartoonProbeDataset(Dataset):\n",
    "    def __init__(self, root_dir, target_attributes, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.target_attributes = target_attributes\n",
    "        \n",
    "        # On liste les images\n",
    "        self.images = sorted([f for f in os.listdir(root_dir) if f.endswith(\".png\")])\n",
    "        self.labels_dict = {attr: [] for attr in target_attributes}\n",
    "        \n",
    "        print(f\"Lazy loading labels for {target_attributes}...\")\n",
    "        \n",
    "        # On lit les CSVs\n",
    "        # Note: Pour aller vite, on pourrait optimiser, mais c'est simple et s√ªr.\n",
    "        count = 0\n",
    "        for img_file in self.images:\n",
    "            csv_file = img_file.replace(\".png\", \".csv\")\n",
    "            csv_path = os.path.join(root_dir, csv_file)\n",
    "            \n",
    "            # Lecture CSV\n",
    "            try:\n",
    "                df = pd.read_csv(csv_path, header=None)\n",
    "                for attr in target_attributes:\n",
    "                    # On cherche la ligne correspondant √† l'attribut\n",
    "                    row = df[df.iloc[:, 0] == attr]\n",
    "                    if not row.empty:\n",
    "                        val = int(row.iloc[0, 1])\n",
    "                        self.labels_dict[attr].append(val)\n",
    "                    else:\n",
    "                        self.labels_dict[attr].append(-1) # Fallback\n",
    "            except Exception:\n",
    "                pass\n",
    "            \n",
    "            count += 1\n",
    "            if count >= SAMPLE_LIMIT: # On ne charge pas tout pour aller vite\n",
    "                break\n",
    "                \n",
    "        # On garde seulement les images qu'on a charg√©es\n",
    "        self.images = self.images[:count]\n",
    "        print(f\"Dataset pr√™t avec {len(self.images)} images.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.images[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        # On retourne un dict de labels pour √™tre flexible\n",
    "        labels = {attr: self.labels_dict[attr][idx] for attr in self.target_attributes}\n",
    "        return img, labels\n",
    "\n",
    "# --- 3. CHARGEMENT DONN√âES ET MOD√àLE ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# On utilise notre classe locale\n",
    "dataset = CartoonProbeDataset(DATA_DIR, PROBE_ATTRIBUTES, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=False) # Shuffle False pour garder l'ordre\n",
    "\n",
    "# Setup du Mod√®le\n",
    "# V√©rifie bien que ces dimensions correspondent √† ton entra√Ænement !\n",
    "model = CCVAE(\n",
    "    img_channels=3,\n",
    "    z_c_dim=16, \n",
    "    z_not_c_dim=64, \n",
    "    num_classes=10 \n",
    ").to(DEVICE)\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "    print(\"‚úÖ Poids du mod√®le charg√©s.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Erreur chargement poids: {e}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# --- 4. EXTRACTION DES VECTEURS Z_C ---\n",
    "print(\"Extraction des vecteurs Latents (z_c)...\")\n",
    "X_zc = []\n",
    "y_stored = {attr: [] for attr in PROBE_ATTRIBUTES}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, labels_batch in loader:\n",
    "        x = x.to(DEVICE)\n",
    "        \n",
    "        # Encodage\n",
    "        h = model.encoder_conv(x)\n",
    "        mu = model.fc_mu(h)\n",
    "        z_c = mu[:, :model.z_c_dim].cpu().numpy() # On prend juste la partie supervis√©e\n",
    "        \n",
    "        X_zc.append(z_c)\n",
    "        \n",
    "        # Stockage des labels\n",
    "        for attr in PROBE_ATTRIBUTES:\n",
    "            y_stored[attr].extend(labels_batch[attr].numpy())\n",
    "\n",
    "X_zc = np.concatenate(X_zc)\n",
    "print(f\"Extraction termin√©e. Shape: {X_zc.shape}\")\n",
    "\n",
    "# --- 5. AUDIT (CLASSIFICATION) ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"{'ATTRIBUT':<15} | {'ACCURACY':<10} | {'BASELINE':<10} | {'STATUS'}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for attr in PROBE_ATTRIBUTES:\n",
    "    y_target = np.array(y_stored[attr])\n",
    "    \n",
    "    # --- PR√âTRAITEMENT SPECIFIQUE ---\n",
    "    if attr == \"glasses\":\n",
    "        # Binaire : 11 = Pas de lunettes, Reste = Lunettes\n",
    "        # On veut pr√©dire \"A des lunettes\" (1) vs \"N'en a pas\" (0)\n",
    "        y_target = (y_target != 11).astype(int)\n",
    "        \n",
    "        # Baseline = Pr√©dire la majorit√©\n",
    "        freq = y_target.mean()\n",
    "        baseline = max(freq, 1-freq)\n",
    "        \n",
    "    else:\n",
    "        # Multiclasse standard\n",
    "        vals, counts = np.unique(y_target, return_counts=True)\n",
    "        baseline = np.max(counts) / np.sum(counts)\n",
    "\n",
    "    # --- ENTRAINEMENT PROBE ---\n",
    "    # R√©gression Logistique sur z_c\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_zc, y_target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    clf = LogisticRegression(max_iter=2000, class_weight='balanced')\n",
    "    clf.fit(X_train, y_train)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    \n",
    "    # --- DIAGNOSTIC ---\n",
    "    if attr == \"hair_color\":\n",
    "        # On veut que ce soit HAUT (c'est la t√¢che supervis√©e)\n",
    "        status = \"‚úÖ OK (Supervis√©)\" if acc > 0.8 else \"‚ö†Ô∏è Faible\"\n",
    "    else:\n",
    "        # On veut que ce soit BAS (proche de la baseline)\n",
    "        # Si acc est beaucoup plus haut que la baseline, c'est de la fuite (Leakage)\n",
    "        threshold = baseline + 0.10 # Marge de 10%\n",
    "        status = \"‚ùå LEAKAGE\" if acc > threshold else \"‚úÖ DISENTANGLED\"\n",
    "\n",
    "    print(f\"{attr:<15} | {acc:.1%}    | {baseline:.1%}    | {status}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd3b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccvae_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
