# CCVAE : Characteristic Capturing Variational Autoencoder

Ce projet est une impl√©mentation **PyTorch** du mod√®le **CCVAE**, bas√©e sur le papier de recherche *"Capturing Label Characteristics in VAEs"* (Joy et al., ICLR 2021)[cite: 1, 11].

L'objectif est de structurer l'espace latent d'un VAE pour s√©parer le **style** (fond, forme globale) des **caract√©ristiques sp√©cifiques** (attributs √©tiquet√©s comme la couleur de cheveux, les lunettes, etc.), permettant ainsi des manipulations pr√©cises de l'image.

## üìÇ Structure du Projet

  * `model.py` : Architecture du CCVAE (Encodeur, D√©codeur, Classifieur Latent)[cite: 11, 14].
  * `loss.py` : Fonction de co√ªt sp√©cifique (Reconstruction + KL Divergence + Perte de supervision)[cite: 153, 154].
  * `dataset.py` : Dataloader personnalis√© pour le **Google Cartoon Set**. G√®re la normalisation des labels.
  * `train_cartoon.py` : Script d'entra√Ænement principal.
  * `visualize.py` : Script de g√©n√©ration de "Latent Traversals" (modification progressive d'un attribut).

## ‚öôÔ∏è Installation

1.  **Pr√©-requis** : Python 3.8+, PyTorch (avec support CUDA recommand√©).
2.  **Installation des d√©pendances** :
    ```bash
    pip install torch torchvision pandas tqdm matplotlib pillow
    ```

## üé® Dataset : Google Cartoon Set

Nous utilisons une version r√©duite (10k images) du Google Cartoon Set pour d√©montrer la capacit√© du mod√®le √† capturer des caract√©ristiques visuelles vari√©es.

1.  T√©l√©chargez le dataset (version 10k): https://google.github.io/cartoonset/download.html
2.  Placez le dossier d√©compress√© dans `cartoonset10k/`.
3.  L'arborescence doit ressembler √† : `./cartoonset10k/cartoonset10k/*.png`

## üöÄ Utilisation

### 1\. Entra√Ænement

Pour lancer l'entra√Ænement du mod√®le :

```bash
python train.py
```

  * Les poids du mod√®le sont sauvegard√©s dans `ccvae_haircolor.pth`.
  * Des reconstructions de test sont sauvegard√©es √† chaque √©poque dans le dossier results/.

### 2\.Inf√©rence & D√©mo (CLI)

Pour tester le mod√®le sur des images sp√©cifiques (Classification, G√©n√©ration, Style Swapping) :

```Bash

python inference.py
```

Note : Vous pouvez modifier les chemins d'images directement dans le main du script.

### 2\.Analyse approfondie (Notebook)
```bash
jupter notebook demo_ccvae.ipynb
```


## üí° Choix Techniques & Impl√©mentation

Contrairement √† certaines approches qui traitent les attributs comme des valeurs continues, nous avons opt√© pour une approche de **Classification Supervis√©e (Cross-Entropy)**.

Pourquoi ?
- **Nature des Donn√©es :** La couleur des cheveux est une donn√©e cat√©gorielle distincte (10 classes). 
- L'utilisation de vecteurs One-Hot combin√©e √† une CrossEntropyLoss permet une s√©paration plus nette des clusters dans l'espace latent qu'une r√©gression MSE.
- **Auxiliary Loss ($\gamma$) :** Pour forcer le mod√®le √† structurer l'espace latent $z_c$ d√®s le d√©but de l'entra√Ænement (et √©viter le "posterior collapse"), nous avons ajout√© une perte de classification auxiliaire avec un poids $\gamma = 20$. Cela garantit que $z_c$ capture explicitement l'information de classe.

### Reconstruction : BCE vs MSE

Nous utilisons la Binary Cross Entropy (BCE) plut√¥t que la Mean Squared Error (MSE) pour la reconstruction des images.

**Pourquoi ?** Les images de type "Cartoon" poss√®dent des aplats de couleurs et des contours nets. La MSE tend √† produire des r√©sultats flous (moyenne des couleurs, gris√¢tre). La BCE p√©nalise fortement les pixels "h√©sitants", produisant des images aux traits nets et au fond blanc pur.

Architecture Latente (Disentanglement)L'espace latent total $z$ est scind√© en deux sous-espaces distincts :$z_c$ (Characteristic Latents) : Dimensions supervis√©es (dim=16). Elles sont forc√©es d'encoder la Couleur des Cheveux via le Conditional Prior $p(z_c|y)$.$z_{\neg c}$ (Contextual Latents) : Dimensions non-supervis√©es (dim=64). Elles capturent tout le reste de l'information (forme du visage, lunettes, style) et suivent un prior gaussien standard $\mathcal{N}(0, I)$.C'est cette s√©paration qui permet le Style Swapping : on peut conserver le $z_{\neg c}$ d'une image A (son visage) et lui injecter le $z_c$ d'une image B (sa couleur).

## üë• Auteurs

  * Farouk YARTAOU
  * Rida ASSALOUH
  * El Mehdi NEZAHI

-----

*Projet r√©alis√© dans le cadre du cours Introduction to Probabilistic Graphical Models and Deep Generative Models , D√©cembre 2025.*